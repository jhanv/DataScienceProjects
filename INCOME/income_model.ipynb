{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT NECCESSARY LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "get_ipython().run_line_magic(\"matplotlib\", \"inline\")\n",
    "sns.set(style = 'white')\n",
    "\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, GridSearchCV, learning_curve\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTING THE DATA FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "combdata = pd.read_csv(\"clean_data\\\\clean_data_r.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPLITTING THE TRAIN AND TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "train shape, (32561, 42) \n test shape (16281, 41)\n32561    0\n32562    0\n32563    1\n32564    1\n32565    0\n        ..\n48837    0\n48838    0\n48839    0\n48840    0\n48841    1\nName: label, Length: 16281, dtype: int64\n"
    }
   ],
   "source": [
    "#selecting/splitting the test and train data \n",
    "train = combdata.loc[combdata['source']==\"train\"]\n",
    "test = combdata.loc[combdata['source']==\"test\"]\n",
    "\n",
    "# Dropping the source column\n",
    "train.drop(columns = ['source'], inplace = True)\n",
    "y_test = test['label']\n",
    "test.drop(labels = ['source', 'label'], axis = 1, inplace = True)\n",
    "print(f' train shape, {train.shape} \\n test shape {test.shape}')\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPLITTING THE LABELS AND THE FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Shape of train features (32561, 41) and train label (32561,)\n"
    }
   ],
   "source": [
    "#splitting the labels and the features\n",
    "\n",
    "x_train = train.drop(columns = ['label'])\n",
    "y_train = train['label'].astype(int)\n",
    "print(f' Shape of train features {x_train.shape} and train label {y_train.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DIFFERENT MODELS TO BE IMPLEMENTED \n",
    "\n",
    "\n",
    "1. K Nearest Neighbour\n",
    "2. Linear Discriminant Analysis\n",
    "3. Support Vector Classifier\n",
    "4. Multi-layer Perceptron classifier\n",
    "5. Extra Trees Classifier\n",
    "6. Logistic Regression\n",
    "7. Decision Trees\n",
    "8. Random Forest\n",
    "9. Gradient Boosting Classifier\n",
    "10. AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 3\n",
    "\n",
    "#creating a list to store the classifiers \n",
    "classifiers = []\n",
    "\n",
    "classifiers.append(KNeighborsClassifier())\n",
    "classifiers.append(LinearDiscriminantAnalysis())\n",
    "classifiers.append(SVC(random_state = random_state))\n",
    "classifiers.append(MLPClassifier(random_state = random_state))\n",
    "classifiers.append(ExtraTreesClassifier(random_state = random_state))\n",
    "classifiers.append(LogisticRegression(random_state = random_state))\n",
    "classifiers.append(DecisionTreeClassifier(random_state = random_state))\n",
    "classifiers.append(RandomForestClassifier(random_state = random_state))\n",
    "classifiers.append(GradientBoostingClassifier(random_state = random_state))\n",
    "classifiers.append(AdaBoostClassifier(DecisionTreeClassifier(random_state = random_state)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CROSS VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validate model with Kfold stratified cross val\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross validation with k-fold\n",
    "cv_results = []\n",
    "\n",
    "cross_val_data = {'Algorithm' : [], 'Cross_Val_Mean' : [], 'Cross_Val_Std':[]}\n",
    "\n",
    "for classifier in classifiers :\n",
    "    scores = cross_val_score(classifier, x_train, y = y_train, scoring = \"accuracy\", cv = kfold, n_jobs = 5 )\n",
    "    cv_results.append(scores)\n",
    "    classifier_name = (classifier.__str__()).split('(')[0]\n",
    "    cross_val_data['Algorithm'].append(classifier_name)\n",
    "    cross_val_data['Cross_Val_Mean'].append(scores.mean())\n",
    "    cross_val_data['Cross_Val_Std'].append(scores.std())\n",
    "    print(f'The ALGORITHM : {(classifier_name)} gives MEAN score : {scores.mean()} and the STANDARD DEVIATION : {scores.std()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PERFORMANCE ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # CREATING A DATA FRAME OF THE CROSS VALIDATION RESULTS\n",
    "\n",
    "# cv_df = pd.DataFrame(cross_val_data)\n",
    "# g = sns.barplot(\"Cross_Val_Mean\", \"Algorithm\", data = cv_df, palette = \"Set3\", orient = \"h\", **{'xerr' : cv_df['Cross_Val_Std']})\n",
    "# g.set_xlabel(\"Mean Accuracy\")\n",
    "# g = g.set_title(\"Cross Validation scores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_df.sort_values(by = 'Cross_Val_Mean', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *  Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n[Parallel(n_jobs=5)]: Done  10 out of  10 | elapsed:   21.0s finished\n      Iter       Train Loss   Remaining Time \n         1           0.8298            8.18s\n         2           0.7485            8.26s\n         3           0.7077            8.31s\n         4           0.6751            8.18s\n         5           0.6552            8.71s\n         6           0.6397            8.73s\n         7           0.6298            8.58s\n         8           0.6214            8.53s\n         9           0.6159            8.36s\n        10           0.6112            8.36s\n        20           0.5770            7.03s\n        30           0.5631            6.06s\n        40           0.5533            5.16s\n        50           0.5464            4.28s\n        60           0.5424            3.41s\n        70           0.5374            2.61s\n        80           0.5333            1.73s\n        90           0.5288            0.87s\n       100           0.5254            0.00s\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False),\n             error_score=nan,\n             estimator=GradientBoostingClassifier(ccp_alpha=0.0,\n                                                  criterion='friedman_mse',\n                                                  init=None, learning_rate=0.1,\n                                                  loss='deviance', max_depth=3,\n                                                  max_features=None,\n                                                  max_leaf_nodes=None,\n                                                  min_impurity_decrease=0.0,\n                                                  min_impurity_split=None,\n                                                  min_samples_leaf=1,\n                                                  min_samples_split=...\n                                                  subsample=1.0, tol=0.0001,\n                                                  validation_fraction=0.1,\n                                                  verbose=0, warm_start=False),\n             iid='deprecated', n_jobs=5,\n             param_grid={'ccp_alpha': [0], 'learning_rate': [0.5],\n                         'loss': ['deviance'], 'max_depth': [3],\n                         'max_features': ['auto'], 'min_impurity_decrease': [0],\n                         'n_estimators': [100], 'verbose': [1]},\n             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n             scoring='roc_auc', verbose=1)"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "GBC = GradientBoostingClassifier()\n",
    "GBC_grid = {\n",
    "    'loss' : ['deviance'],\n",
    "    'learning_rate' : [0.5],\n",
    "    'n_estimators' : [100],\n",
    "    'max_depth' : [3],\n",
    "    'min_impurity_decrease' : [0],\n",
    "    'max_features' : ['auto'],\n",
    "    'verbose' : [1],\n",
    "    'ccp_alpha' : [0],\n",
    "}\n",
    "\n",
    "\n",
    "gsgbc =  GridSearchCV(GBC, GBC_grid, cv = kfold, scoring = 'roc_auc', n_jobs = 5, verbose = 1)\n",
    "gsgbc.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "GradientBoostingClassifier(ccp_alpha=0, criterion='friedman_mse', init=None,\n                           learning_rate=0.5, loss='deviance', max_depth=3,\n                           max_features='auto', max_leaf_nodes=None,\n                           min_impurity_decrease=0, min_impurity_split=None,\n                           min_samples_leaf=1, min_samples_split=2,\n                           min_weight_fraction_leaf=0.0, n_estimators=100,\n                           n_iter_no_change=None, presort='deprecated',\n                           random_state=None, subsample=1.0, tol=0.0001,\n                           validation_fraction=0.1, verbose=1,\n                           warm_start=False)\n0.9268635317334992\n{'ccp_alpha': 0, 'learning_rate': 0.5, 'loss': 'deviance', 'max_depth': 3, 'max_features': 'auto', 'min_impurity_decrease': 0, 'n_estimators': 100, 'verbose': 1}\n"
    }
   ],
   "source": [
    "print(gsgbc.best_estimator_)\n",
    "print(gsgbc.best_score_)\n",
    "print(gsgbc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n[Parallel(n_jobs=5)]: Done  10 out of  10 | elapsed:  3.0min finished\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False),\n             error_score=nan,\n             estimator=MLPClassifier(activation='relu', alpha=0.0001,\n                                     batch_size='auto', beta_1=0.9,\n                                     beta_2=0.999, early_stopping=False,\n                                     epsilon=1e-08, hidden_layer_sizes=(100,),\n                                     learning_rate='constant',\n                                     learning_rate_init=0.001, max_fun=15000,\n                                     max_iter=200, momentum=0.9,\n                                     n_iter_no...\n                                     solver='adam', tol=0.0001,\n                                     validation_fraction=0.1, verbose=False,\n                                     warm_start=False),\n             iid='deprecated', n_jobs=5,\n             param_grid={'activation': ['logistic'], 'alpha': [0.01],\n                         'beta_1': [0.85], 'beta_2': [0.99],\n                         'learning_rate': ['adaptive'], 'momentum': [0.5],\n                         'nesterovs_momentum': [True], 'solver': ['adam']},\n             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n             scoring='roc_auc', verbose=1)"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "MLP = MLPClassifier()\n",
    "\n",
    "MLP_grid = {\n",
    "    'activation' : [ 'logistic'],\n",
    "    'solver' : ['adam'],\n",
    "    'alpha' : [0.01],\n",
    "    'learning_rate' : ['adaptive'],\n",
    "    'momentum' : [0.5],\n",
    "    'nesterovs_momentum' : [True],\n",
    "    'beta_1' : [0.85],\n",
    "    'beta_2' : [0.99],\n",
    "}\n",
    "\n",
    "gsmlp = GridSearchCV(MLP, MLP_grid, cv = kfold, scoring = 'roc_auc', n_jobs = 5, verbose = 1)\n",
    "gsmlp.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "MLPClassifier(activation='logistic', alpha=0.01, batch_size='auto', beta_1=0.85,\n              beta_2=0.99, early_stopping=False, epsilon=1e-08,\n              hidden_layer_sizes=(100,), learning_rate='adaptive',\n              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n              momentum=0.5, n_iter_no_change=10, nesterovs_momentum=True,\n              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n              tol=0.0001, validation_fraction=0.1, verbose=False,\n              warm_start=False)\n0.9117043602175118\n{'activation': 'logistic', 'alpha': 0.01, 'beta_1': 0.85, 'beta_2': 0.99, 'learning_rate': 'adaptive', 'momentum': 0.5, 'nesterovs_momentum': True, 'solver': 'adam'}\n"
    }
   ],
   "source": [
    "print(gsmlp.best_estimator_)\n",
    "print(gsmlp.best_score_)\n",
    "print(gsmlp.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n[Parallel(n_jobs=5)]: Done  10 out of  10 | elapsed:   37.9s finished\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False),\n             error_score=nan,\n             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n                                              class_weight=None,\n                                              criterion='gini', max_depth=None,\n                                              max_features='auto',\n                                              max_leaf_nodes=None,\n                                              max_samples=None,\n                                              min_impurity_decrease=0.0,\n                                              min_impurity_split=None,\n                                              min_samples_leaf=1,\n                                              min_samples_split=2...\n                                              verbose=0, warm_start=False),\n             iid='deprecated', n_jobs=5,\n             param_grid={'bootstrap': [True], 'ccp_alpha': [0],\n                         'class_weight': ['balanced'], 'criterion': ['gini'],\n                         'max_features': ['auto'], 'min_impurity_decrease': [0],\n                         'min_samples_split': [20], 'n_estimators': [200],\n                         'oob_score': [True]},\n             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n             scoring='roc_auc', verbose=1)"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "RFC = RandomForestClassifier(random_state = random_state)\n",
    "\n",
    "RFC_grid = {\n",
    "    'n_estimators' : [200],\n",
    "    'criterion' : [\"gini\"],\n",
    "    'min_samples_split' : [20],\n",
    "    'max_features' : [\"auto\"],\n",
    "    'min_impurity_decrease' : [0],\n",
    "    'bootstrap' : [True],\n",
    "    'oob_score' : [True],\n",
    "    'class_weight' : [\"balanced\"],\n",
    "    'ccp_alpha' : [0],\n",
    "}\n",
    "\n",
    "\n",
    "gsrfc =  GridSearchCV(RFC, RFC_grid, cv = kfold, scoring = 'roc_auc', n_jobs = 5, verbose = 1)\n",
    "gsrfc.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "RandomForestClassifier(bootstrap=True, ccp_alpha=0, class_weight='balanced',\n                       criterion='gini', max_depth=None, max_features='auto',\n                       max_leaf_nodes=None, max_samples=None,\n                       min_impurity_decrease=0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=20,\n                       min_weight_fraction_leaf=0.0, n_estimators=200,\n                       n_jobs=None, oob_score=True, random_state=3, verbose=0,\n                       warm_start=False)\n0.9128311155196881\n{'bootstrap': True, 'ccp_alpha': 0, 'class_weight': 'balanced', 'criterion': 'gini', 'max_features': 'auto', 'min_impurity_decrease': 0, 'min_samples_split': 20, 'n_estimators': 200, 'oob_score': True}\n"
    }
   ],
   "source": [
    "print(gsrfc.best_estimator_)\n",
    "print(gsrfc.best_score_)\n",
    "print(gsrfc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Fitting 10 folds for each of 2 candidates, totalling 20 fits\n[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n[Parallel(n_jobs=5)]: Done  20 out of  20 | elapsed: 87.3min finished\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "GridSearchCV(cv=StratifiedKFold(n_splits=10, random_state=None, shuffle=False),\n             error_score=nan,\n             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n                           class_weight=None, coef0=0.0,\n                           decision_function_shape='ovr', degree=3,\n                           gamma='scale', kernel='rbf', max_iter=-1,\n                           probability=False, random_state=3, shrinking=True,\n                           tol=0.001, verbose=False),\n             iid='deprecated', n_jobs=5,\n             param_grid={'decision_function_shape': ['ovo', 'ovr'],\n                         'degree': [3], 'gamma': ['scale'],\n                         'kernel': ['linear'], 'probability': [True]},\n             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n             scoring='roc_auc', verbose=1)"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "svc = SVC(random_state = random_state)\n",
    "\n",
    "svc_grid = {\n",
    "    'kernel' : ['linear'],\n",
    "    'degree' : [3],\n",
    "    'gamma' : ['scale'],\n",
    "    'probability' : [True],\n",
    "    'decision_function_shape' : ['ovo'],\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "gssvc =  GridSearchCV(svc, svc_grid, cv = kfold, scoring = 'roc_auc', n_jobs = 5, verbose = 1)\n",
    "gssvc.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n    decision_function_shape='ovo', degree=3, gamma='scale', kernel='linear',\n    max_iter=-1, probability=True, random_state=3, shrinking=True, tol=0.001,\n    verbose=False)\n0.891943772757155\n{'decision_function_shape': 'ovo', 'degree': 3, 'gamma': 'scale', 'kernel': 'linear', 'probability': True}\n"
    }
   ],
   "source": [
    "print(gssvc.best_estimator_)\n",
    "print(gssvc.best_score_)\n",
    "print(gssvc.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FEATURE IMPORTANCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEFINING THE MODEL WITH BEST PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 3\n",
    "\n",
    "\n",
    "#GradientBoostingClassifier\n",
    "gbc_best = GradientBoostingClassifier(ccp_alpha=0, criterion='friedman_mse', init=None,\n",
    "                           learning_rate=0.5, loss='deviance', max_depth=3,\n",
    "                           max_features='auto', max_leaf_nodes=None,\n",
    "                           min_impurity_decrease=0, min_impurity_split=None,\n",
    "                           min_samples_leaf=1, min_samples_split=2,\n",
    "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
    "                           n_iter_no_change=None, presort='deprecated',\n",
    "                           random_state=None, subsample=1.0, tol=0.0001,\n",
    "                           validation_fraction=0.1, verbose=0,\n",
    "                           warm_start=False)\n",
    "\n",
    "#RandomForestClassifier\n",
    "rfc_best = RandomForestClassifier(bootstrap=True, ccp_alpha=0, class_weight='balanced',\n",
    "                       criterion='gini', max_depth=None, max_features='auto',\n",
    "                       max_leaf_nodes=None, max_samples=None,\n",
    "                       min_impurity_decrease=0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=20,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
    "                       n_jobs=None, oob_score=True, random_state=3, verbose=0,\n",
    "                       warm_start=False)\n",
    "\n",
    "#MLPClassifier\n",
    "mlp_best = MLPClassifier(activation='logistic', alpha=0.01, batch_size='auto', beta_1=0.85,\n",
    "              beta_2=0.99, early_stopping=False, epsilon=1e-08,\n",
    "              hidden_layer_sizes=(100,), learning_rate='adaptive',\n",
    "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
    "              momentum=0.5, n_iter_no_change=10, nesterovs_momentum=True,\n",
    "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
    "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
    "              warm_start=False)\n",
    "\n",
    "#SVC \n",
    "svc_best = SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovo', degree=3, gamma='scale', kernel='linear',\n",
    "    max_iter=-1, probability=True, random_state=3, shrinking=True, tol=0.001,\n",
    "    verbose=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creating the dictionaries for all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Iter       Train Loss   Remaining Time \n         1           0.8298            5.42s\n         2           0.7485            4.79s\n         3           0.7077            4.58s\n         4           0.6751            5.31s\n         5           0.6552            5.23s\n         6           0.6397            5.06s\n         7           0.6298            4.89s\n         8           0.6214            4.71s\n         9           0.6159            4.60s\n        10           0.6112            4.50s\n        20           0.5770            3.67s\n        30           0.5631            3.13s\n        40           0.5533            2.91s\n        50           0.5464            2.36s\n        60           0.5424            1.87s\n        70           0.5374            1.38s\n        80           0.5333            0.94s\n        90           0.5288            0.48s\n       100           0.5254            0.00s\n"
    }
   ],
   "source": [
    "classifier_dic = { 'classifiers' : [gbc_best, rfc_best, mlp_best, svc_best], 'classifier_name' : []}\n",
    "\n",
    "#Training and Naming classifier\n",
    "for num, classifier in enumerate(classifier_dic['classifiers']):\n",
    "    classifier_dic['classifier_name'].append((classifier.__str__()).split('(')[0])\n",
    "    classifier_dic['classifiers'][num] = classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = ncols = 2\n",
    "\n",
    "fig, axes = plt.subplots(nrows = nrows, ncols = ncols, sharex = True, figsize = (15, 15))\n",
    "\n",
    "classifier_number = 0\n",
    "for row in range(nrows):\n",
    "    for col in range(ncols):\n",
    "        classifier = classifier_dic['classifiers'][classifier_number]\n",
    "        name = classifier_dic['classifier_name'][classifier_number]\n",
    "        imp_features_pos = np.argsort(classifier.feature_importances_)[::1]\n",
    "        g = sns.barplot(x = classifier.feature_importances_[imp_features_pos], y = x_train.columns[imp_features_pos], orient = 'h', ax = axes[row][col])\n",
    "\n",
    "        g.set_xlabel('Feature Importance', fontsize = 10)  \n",
    "        g.set_ylabel('Feature Names', fontsize = 10)  \n",
    "        g.set_title(f'{name}', fontsize = 11) \n",
    "        g.tick_params(labelsize = 8)\n",
    "\n",
    "        classifier_number += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VOTING CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "VotingClassifier(estimators=[('GradientBoostingClassifier',\n                              GradientBoostingClassifier(ccp_alpha=0,\n                                                         criterion='friedman_mse',\n                                                         init=None,\n                                                         learning_rate=0.5,\n                                                         loss='deviance',\n                                                         max_depth=3,\n                                                         max_features='auto',\n                                                         max_leaf_nodes=None,\n                                                         min_impurity_decrease=0,\n                                                         min_impurity_split=None,\n                                                         min_samples_leaf=1,\n                                                         min_samples_split=2,\n                                                         min_weight_fraction_leaf=0.0,\n                                                         n_estimators=10...\n                                                     oob_score=True,\n                                                     random_state=3, verbose=0,\n                                                     warm_start=False)),\n                             ('SVC',\n                              SVC(C=1.0, break_ties=False, cache_size=200,\n                                  class_weight=None, coef0=0.0,\n                                  decision_function_shape='ovo', degree=3,\n                                  gamma='scale', kernel='linear', max_iter=-1,\n                                  probability=True, random_state=3,\n                                  shrinking=True, tol=0.001, verbose=False))],\n                 flatten_transform=True, n_jobs=4, voting='soft', weights=None)"
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "combined_classifier = VotingClassifier(estimators=[('GradientBoostingClassifier', gbc_best),('MLPClassifier', mlp_best), ('RandomForestClassifier', rfc_best), ('SVC', svc_best)], voting='soft', n_jobs=4)\n",
    "\n",
    "combined_classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The accuracy is 0.8648117437503838\n"
    }
   ],
   "source": [
    "y_pred = combined_classifier.predict(test)\n",
    "accuracy = (y_pred == y_test).sum()/len(y_pred)\n",
    "print(f'The accuracy is {accuracy}')\n",
    "\n",
    "# Exporting to a cleaned data folder\n",
    "curr_dir = os.getcwd()\n",
    "path = os.path.join(curr_dir, 'predictions\\\\prediction_1.csv')\n",
    "prediction = pd.Series(y_pred, name = 'Prediction') \n",
    "prediction.to_csv(path, index = False, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[11529   906]\n [ 1295  2551]]\n"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix \n",
    "\n",
    "results = confusion_matrix(y_test, y_pred)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}